# ui/pages/search_interactive.py
"""Page de recherche avec syst√®me de dialogue interactif."""
import streamlit as st
from datetime import datetime
from typing import Dict, List, Any, Optional

# Import des modules
from core.search.dialogue_manager import DialogueManager
from core.llm.multi_llm_manager import MultiLLMManager  # √Ä cr√©er
from core.security.rgpd_manager import RGPDManager


class InteractiveSearchPage:
    """G√®re la page de recherche avec dialogue interactif."""
    
    def __init__(self):
        self.dialogue_manager = DialogueManager()
        self.multi_llm = MultiLLMManager()
        self.rgpd = RGPDManager()
        
        # Initialisation de l'√©tat de session
        if 'search_state' not in st.session_state:
            st.session_state.search_state = 'waiting'  # waiting, clarifying, processing, complete
        if 'current_query' not in st.session_state:
            st.session_state.current_query = ""
        if 'clarification_questions' not in st.session_state:
            st.session_state.clarification_questions = []
        if 'user_responses' not in st.session_state:
            st.session_state.user_responses = {}
        if 'search_results' not in st.session_state:
            st.session_state.search_results = None
        if 'question_round' not in st.session_state:
            st.session_state.question_round = 0
    
    def render(self, username: str):
        """Affiche la page de recherche interactive."""
        st.title("üîç Assistant de recherche intelligent")
        
        # Afficher l'√©tat actuel
        self._display_status()
        
        # Zone de requ√™te principale
        self._render_search_input()
        
        # Zone de dialogue si en mode clarification
        if st.session_state.search_state == 'clarifying':
            self._render_clarification_dialogue()
        
        # Affichage des r√©sultats si disponibles
        if st.session_state.search_state == 'complete' and st.session_state.search_results:
            self._render_results()
        
        # Historique de conversation dans la sidebar
        with st.sidebar:
            self._render_conversation_history()
    
    def _display_status(self):
        """Affiche l'√©tat actuel du processus."""
        status_messages = {
            'waiting': "üí≠ En attente de votre requ√™te...",
            'clarifying': "ü§î J'ai besoin de quelques pr√©cisions pour mieux vous aider",
            'processing': "‚ö° Traitement en cours avec les IA s√©lectionn√©es...",
            'complete': "‚úÖ Recherche termin√©e"
        }
        
        if st.session_state.search_state in status_messages:
            if st.session_state.search_state == 'clarifying':
                st.info(status_messages[st.session_state.search_state])
            elif st.session_state.search_state == 'processing':
                st.warning(status_messages[st.session_state.search_state])
            elif st.session_state.search_state == 'complete':
                st.success(status_messages[st.session_state.search_state])
    
    def _render_search_input(self):
        """Affiche la barre de recherche principale."""
        # Container pour la recherche
        with st.container():
            col1, col2 = st.columns([5, 1])
            
            with col1:
                # Zone de texte pour la requ√™te
                query = st.text_area(
                    "Votre requ√™te",
                    value=st.session_state.current_query,
                    height=100,
                    placeholder=(
                        "D√©crivez ce que vous cherchez ou ce que vous voulez faire...\n"
                        "Exemples :\n"
                        "- @dossier_martin analyse les contradictions dans les auditions\n"
                        "- R√©dige une plainte pour escroquerie\n"
                        "- Trouve la jurisprudence sur le blanchiment aggrav√©"
                    ),
                    key="main_query_input",
                    disabled=st.session_state.search_state in ['clarifying', 'processing']
                )
            
            with col2:
                st.write("")  # Espaceur pour alignement
                # Bouton d'ex√©cution imm√©diate
                force_execute = st.button(
                    "‚ö° Ex√©cuter\nsans questions",
                    key="force_execute",
                    help="Lance la recherche imm√©diatement sans poser de questions",
                    disabled=st.session_state.search_state == 'processing'
                )
            
            # Options de recherche
            with st.expander("‚öôÔ∏è Options avanc√©es", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    # S√©lection des mod√®les IA
                    selected_models = st.multiselect(
                        "ü§ñ Mod√®les IA √† utiliser",
                        options=["GPT-4o", "Claude Opus 4", "Perplexity", "Mistral", "Gemini", "DeepSeek"],
                        default=["GPT-4o", "Claude Opus 4"],
                        key="selected_models"
                    )
                    
                    # Sources de recherche
                    search_sources = st.multiselect(
                        "üìö Sources de recherche",
                        options=["Documents vectoris√©s", "Legifrance", "Judilibre", "Internet"],
                        default=["Documents vectoris√©s"],
                        key="search_sources"
                    )
                
                with col2:
                    # Mode de fusion
                    fusion_mode = st.select_slider(
                        "üîÑ Mode de fusion des r√©ponses",
                        options=["Comparatif", "Synth√©tique", "Contradictoire", "Exhaustif", "Consensuel"],
                        value="Synth√©tique",
                        key="fusion_mode"
                    )
                    
                    # Estimation des co√ªts
                    estimate_cost = st.checkbox(
                        "üí∞ Estimer le co√ªt avant ex√©cution",
                        value=True,
                        key="estimate_cost"
                    )
            
            # Boutons d'action
            col1, col2, col3 = st.columns([2, 2, 2])
            
            with col1:
                if st.button(
                    "üîç Analyser ma requ√™te",
                    type="primary",
                    disabled=st.session_state.search_state != 'waiting' or not query,
                    use_container_width=True
                ):
                    self._start_analysis(query, username)
            
            with col2:
                if st.button(
                    "üîÑ Nouvelle recherche",
                    disabled=st.session_state.search_state == 'processing',
                    use_container_width=True
                ):
                    self._reset_search()
            
            with col3:
                if st.button(
                    "üìã Voir l'historique",
                    use_container_width=True
                ):
                    st.session_state.show_history = not st.session_state.get('show_history', False)
            
            # Forcer l'ex√©cution si demand√©
            if force_execute and query:
                self._execute_search(query, username, skip_clarification=True)
    
    def _start_analysis(self, query: str, username: str):
        """D√©marre l'analyse de la requ√™te."""
        st.session_state.current_query = query
        st.session_state.search_state = 'clarifying'
        
        # Analyser la requ√™te
        analysis = self.dialogue_manager.analyze_query(query)
        
        # Si haute confiance ou pas besoin de clarification
        if analysis['confidence'] > 0.8 or not analysis['needs_clarification']:
            self._execute_search(query, username, skip_clarification=True)
        else:
            # Pr√©parer les questions
            st.session_state.clarification_questions = analysis['questions']
            st.session_state.question_round = 1
            st.rerun()
    
    def _render_clarification_dialogue(self):
        """Affiche le dialogue de clarification."""
        st.markdown("### üí¨ Dialogue de pr√©cision")
        
        # Afficher le round de questions
        st.caption(f"Round {st.session_state.question_round} de questions")
        
        # Container pour les questions
        with st.form("clarification_form"):
            responses = {}
            
            # Afficher chaque question
            for i, question in enumerate(st.session_state.clarification_questions):
                st.markdown(f"**{i+1}. {question['text']}**")
                
                if question['type'] == 'choice':
                    responses[question['id']] = st.selectbox(
                        "",
                        options=[""] + question['options'],
                        key=f"q_{question['id']}",
                        label_visibility="collapsed"
                    )
                
                elif question['type'] == 'text':
                    responses[question['id']] = st.text_input(
                        "",
                        key=f"q_{question['id']}",
                        placeholder="Votre r√©ponse...",
                        label_visibility="collapsed"
                    )
                
                elif question['type'] == 'date':
                    responses[question['id']] = st.date_input(
                        "",
                        key=f"q_{question['id']}",
                        label_visibility="collapsed"
                    )
                
                elif question['type'] == 'multiselect':
                    responses[question['id']] = st.multiselect(
                        "",
                        options=question['options'],
                        key=f"q_{question['id']}",
                        label_visibility="collapsed"
                    )
                
                st.write("")  # Espacement
            
            # Boutons d'action
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                submit = st.form_submit_button(
                    "‚úÖ R√©pondre",
                    type="primary",
                    use_container_width=True
                )
            
            with col2:
                more_questions = st.form_submit_button(
                    "‚ûï Plus de questions",
                    use_container_width=True
                )
            
            with col3:
                execute_now = st.form_submit_button(
                    "‚ö° Ex√©cuter maintenant",
                    use_container_width=True
                )
            
            with col4:
                cancel = st.form_submit_button(
                    "‚ùå Annuler",
                    use_container_width=True
                )
        
        # Traiter les actions
        if submit:
            # Sauvegarder les r√©ponses
            st.session_state.user_responses.update(responses)
            
            # V√©rifier si on a besoin de plus de questions
            if self.dialogue_manager.should_ask_more_questions(st.session_state.user_responses):
                # G√©n√©rer des questions de suivi
                followup = self.dialogue_manager.generate_followup_questions(
                    st.session_state.current_query,
                    st.session_state.user_responses
                )
                st.session_state.clarification_questions = followup
                st.session_state.question_round += 1
                st.rerun()
            else:
                # Pr√™t √† ex√©cuter
                self._execute_search(
                    st.session_state.current_query,
                    st.session_state.get('username', 'unknown')
                )
        
        elif more_questions:
            # G√©n√©rer plus de questions
            st.session_state.user_responses.update(responses)
            followup = self.dialogue_manager.generate_followup_questions(
                st.session_state.current_query,
                st.session_state.user_responses
            )
            st.session_state.clarification_questions.extend(followup)
            st.session_state.question_round += 1
            st.rerun()
        
        elif execute_now:
            # Ex√©cuter avec les r√©ponses actuelles
            st.session_state.user_responses.update(responses)
            self._execute_search(
                st.session_state.current_query,
                st.session_state.get('username', 'unknown')
            )
        
        elif cancel:
            self._reset_search()
    
    def _execute_search(self, query: str, username: str, skip_clarification: bool = False):
        """Ex√©cute la recherche avec tous les param√®tres."""
        st.session_state.search_state = 'processing'
        
        # Logger l'action
        self.rgpd.log_access(
            username,
            "search_execution",
            details={
                "query": query[:200],
                "models": st.session_state.get('selected_models', []),
                "clarifications": st.session_state.user_responses
            }
        )
        
        # Estimation du co√ªt si demand√©
        if st.session_state.get('estimate_cost', True):
            cost_estimate = self._estimate_query_cost(query)
            st.info(f"üí∞ Co√ªt estim√© : {cost_estimate:.2f} ‚Ç¨ (environ {cost_estimate * 33333:.0f} tokens)")
        
        # Simuler le traitement (√† remplacer par l'appel r√©el)
        with st.spinner("Traitement en cours..."):
            # Progress bar
            progress = st.progress(0)
            
            # Simuler l'interrogation de chaque mod√®le
            models = st.session_state.get('selected_models', ['GPT-4o'])
            for i, model in enumerate(models):
                progress.progress((i + 1) / len(models))
                st.write(f"ü§ñ Interrogation de {model}...")
            
            # Simuler la fusion
            st.write("üîÑ Fusion des r√©ponses...")
            
            # R√©sultats simul√©s
            results = {
                'query': query,
                'models_used': models,
                'fusion_mode': st.session_state.get('fusion_mode', 'Synth√©tique'),
                'clarifications': st.session_state.user_responses,
                'responses': self._generate_mock_responses(models),
                'sources': self._generate_mock_sources(),
                'timestamp': datetime.now(),
                'cost': cost_estimate if st.session_state.get('estimate_cost') else None
            }
            
            st.session_state.search_results = results
            st.session_state.search_state = 'complete'
            st.rerun()
    
    def _render_results(self):
        """Affiche les r√©sultats de la recherche."""
        results = st.session_state.search_results
        
        st.markdown("### üìä R√©sultats de la recherche")
        
        # M√©tadonn√©es de la recherche
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Mod√®les utilis√©s", len(results['models_used']))
        with col2:
            st.metric("Sources consult√©es", len(results['sources']))
        with col3:
            if results.get('cost'):
                st.metric("Co√ªt", f"{results['cost']:.2f} ‚Ç¨")
        
        # Onglets pour les r√©sultats
        tabs = st.tabs(results['models_used'] + [f"üîÄ Fusion {results['fusion_mode']}"])
        
        # R√©ponses individuelles
        for i, (tab, model) in enumerate(zip(tabs[:-1], results['models_used'])):
            with tab:
                response = results['responses'][model]
                
                # En-t√™te du mod√®le
                st.markdown(f"#### R√©ponse de {model}")
                
                # Contenu de la r√©ponse
                st.markdown(response['content'])
                
                # Sources utilis√©es
                if response.get('sources'):
                    st.markdown("**Sources cit√©es :**")
                    for source in response['sources']:
                        st.write(f"- üìÑ {source['document']} (page {source['page']})")
                
                # M√©triques
                col1, col2 = st.columns(2)
                with col1:
                    st.caption(f"‚è±Ô∏è Temps: {response['time']:.1f}s")
                with col2:
                    st.caption(f"üî§ Tokens: {response['tokens']:,}")
        
        # Onglet fusion
        with tabs[-1]:
            st.markdown(f"#### Fusion {results['fusion_mode'].lower()} des r√©ponses")
            
            # Afficher la fusion selon le mode
            if results['fusion_mode'] == 'Synth√©tique':
                st.info("üîÄ **Synth√®se unifi√©e des r√©ponses**")
                st.markdown(self._generate_synthetic_fusion(results['responses']))
            
            elif results['fusion_mode'] == 'Comparatif':
                st.info("üìä **Analyse comparative des r√©ponses**")
                self._render_comparative_analysis(results['responses'])
            
            elif results['fusion_mode'] == 'Contradictoire':
                st.warning("‚ö†Ô∏è **Points de contradiction d√©tect√©s**")
                self._render_contradictions(results['responses'])
            
            # Actions sur les r√©sultats
            st.markdown("### üéØ Actions")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üìÑ G√©n√©rer un rapport", use_container_width=True):
                    st.info("G√©n√©ration du rapport en cours...")
            
            with col2:
                if st.button("üíæ Sauvegarder les r√©sultats", use_container_width=True):
                    st.success("R√©sultats sauvegard√©s!")
            
            with col3:
                if st.button("üîÑ Affiner la recherche", use_container_width=True):
                    st.session_state.search_state = 'clarifying'
                    st.rerun()
    
    def _render_conversation_history(self):
        """Affiche l'historique de conversation dans la sidebar."""
        if st.session_state.get('show_history', False):
            st.markdown("### üìú Historique")
            
            # Historique simul√©
            history = [
                {"time": "10:45", "query": "Analyse contradictions dossier Martin"},
                {"time": "09:30", "query": "R√©dige conclusions nullit√© PV"},
                {"time": "Hier", "query": "Jurisprudence blanchiment aggrav√©"},
            ]
            
            for item in history:
                with st.expander(f"üïê {item['time']}"):
                    st.write(item['query'])
                    if st.button("Relancer", key=f"rerun_{item['time']}"):
                        st.session_state.current_query = item['query']
                        self._reset_search()
                        st.rerun()
    
    def _reset_search(self):
        """R√©initialise l'√©tat de la recherche."""
        st.session_state.search_state = 'waiting'
        st.session_state.clarification_questions = []
        st.session_state.user_responses = {}
        st.session_state.search_results = None
        st.session_state.question_round = 0
    
    def _estimate_query_cost(self, query: str) -> float:
        """Estime le co√ªt d'une requ√™te."""
        # Estimation basique (√† remplacer par un vrai calcul)
        base_cost = 0.01  # par mod√®le
        models_count = len(st.session_state.get('selected_models', ['GPT-4o']))
        query_length_factor = len(query) / 100
        
        return base_cost * models_count * (1 + query_length_factor)
    
    def _generate_mock_responses(self, models: List[str]) -> Dict[str, Any]:
        """G√©n√®re des r√©ponses simul√©es pour la d√©mo."""
        responses = {}
        for model in models:
            responses[model] = {
                'content': f"R√©ponse simul√©e de {model} concernant la requ√™te...",
                'sources': [
                    {'document': 'PV_audition_001.pdf', 'page': 12},
                    {'document': 'Conclusions_adverses.docx', 'page': 5}
                ],
                'time': 2.3,
                'tokens': 1250,
                'confidence': 0.85
            }
        return responses
    
    def _generate_mock_sources(self) -> List[Dict[str, Any]]:
        """G√©n√®re des sources simul√©es."""
        return [
            {'type': 'document', 'name': 'PV_audition_001.pdf', 'relevance': 0.9},
            {'type': 'jurisprudence', 'name': 'Cass. Crim. 2023', 'relevance': 0.8},
            {'type': 'article', 'name': 'Art. 432-11 CP', 'relevance': 0.95}
        ]
    
    def _generate_synthetic_fusion(self, responses: Dict[str, Any]) -> str:
        """G√©n√®re une fusion synth√©tique des r√©ponses."""
        return """
        D'apr√®s l'analyse crois√©e des diff√©rents mod√®les d'IA, voici la synth√®se :
        
        **Points de consensus :**
        - Tous les mod√®les s'accordent sur l'existence d'une contradiction majeure dans les d√©clarations
        - La chronologie des faits pr√©sente des incoh√©rences notables
        
        **√âl√©ments compl√©mentaires :**
        - GPT-4o souligne particuli√®rement l'aspect proc√©dural
        - Claude met en avant les implications juridiques
        
        **Recommandations unanimes :**
        1. Approfondir l'analyse des pi√®ces 12 √† 15
        2. V√©rifier la validit√© des proc√®s-verbaux
        3. Pr√©parer une argumentation sur la nullit√© potentielle
        """
    
    def _render_comparative_analysis(self, responses: Dict[str, Any]):
        """Affiche une analyse comparative des r√©ponses."""
        # Tableau comparatif
        comparison_data = []
        for model, response in responses.items():
            comparison_data.append({
                'Mod√®le': model,
                'Confiance': f"{response.get('confidence', 0.8)*100:.0f}%",
                'Tokens': response['tokens'],
                'Sources': len(response.get('sources', []))
            })
        
        st.dataframe(comparison_data, use_container_width=True)
    
    def _render_contradictions(self, responses: Dict[str, Any]):
        """Affiche les contradictions d√©tect√©es."""
        st.write("**Contradictions identifi√©es :**")
        
        contradictions = [
            {
                'point': "Date de la transaction",
                'model1': "GPT-4o : 15 mars 2024",
                'model2': "Claude : 18 mars 2024",
                'severity': "high"
            },
            {
                'point': "Montant concern√©",
                'model1': "Perplexity : 150,000 ‚Ç¨",
                'model2': "Mistral : 145,000 ‚Ç¨",
                'severity': "low"
            }
        ]
        
        for contradiction in contradictions:
            severity_color = "üî¥" if contradiction['severity'] == 'high' else "üü°"
            st.write(f"{severity_color} **{contradiction['point']}**")
            st.write(f"  - {contradiction['model1']}")
            st.write(f"  - {contradiction['model2']}")


# Fonction pour int√©grer dans l'app principale
def render_interactive_search_page(username: str):
    """Point d'entr√©e pour la page de recherche interactive."""
    page = InteractiveSearchPage()
    page.render(username)
